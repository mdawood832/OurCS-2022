# OurCS-2022
3-day Research Focused Workshop at Carnegie Mellon University

Worked in a team to develop an automated web crawling tool that scrapes federal and state-level government websites to identify government regulations and guidelines concerning the in-house uses of AI/ML technologies. We were interested in how these agencies safeguard against bias and discriminatory impacts of these technologies.

# Duration
October 17 to October 20, 2022

# Role
Researcher and Writer

# Team
4 Undergraduate Students and 2 PHD mentors

# Tools

![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)



# Web Crawler
https://colab.research.google.com/drive/1SwHqYTMgP4Z2IEMX13K1c4WtwrZiorpp?usp=sharing <br> 
We built an automated web crawling tool using Python and Google Colab.
![image](https://github.com/mdawood832/OurCS-2022/assets/101743220/d752b0ce-9db5-4d7b-90ce-bf08c7630f9e)


# Research Questions
1. What fraction of the identified webpages were relevant?
2. Among those, how many contained concrete processes and guidelines to guard against AI/ML technologies?
3. How do you define what constitutes a process or guideline that could help guard against AI/ML bias?
4. What were those steps? (For example, what regulatory considerations, practices, and processes do the government documents suggest help guard against AI/ML bias?

Research Organized Through Mural
   ![image](https://github.com/mdawood832/OurCS-2022/assets/101743220/e60e26f6-9f1c-4f22-95dc-91515c0e6fbd)


# Poster Presented 
https://docs.google.com/presentation/d/1Pfyca-juJ4KVtgBZdGpDZGCxV5IbuUNQ/edit?usp=sharing&ouid=107605483287758919281&rtpof=true&sd=true <br>
Presented poster in front of all undergraduate students, mentors, and event planners!
![image](https://github.com/mdawood832/OurCS-2022/assets/101743220/7b31d41b-2b2d-46ec-9593-2c7c5a0fc07f)



